{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjUTW4c2LmKVn5GTCIDKGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArepalliSukeerthi/Tree_species_classification/blob/main/tree_specification2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZQh7PCQbRvH"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/Tree_Species_Dataset/train'\n",
        "test_dir = '/content/drive/MyDrive/Tree_Species_Dataset/test'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Tree_Species_Dataset/train'\n",
        "test_dir = '/content/drive/MyDrive/Tree_Species_Dataset/test'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP0dw--6cmRW",
        "outputId": "ec5faff2-3fdb-442e-aff4-ccee059e24e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "test_data = test_datagen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_data.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, validation_data=test_data, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9t7DllOfFPm",
        "outputId": "b2e7fb92-745e-49d2-92a8-0cb760d29465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1607 images belonging to 31 classes.\n",
            "Found 1086 images belonging to 31 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.0408 - loss: 5.3857 - val_accuracy: 0.1142 - val_loss: 3.1306\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.1351 - loss: 3.1685 - val_accuracy: 0.2330 - val_loss: 2.8028\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.2076 - loss: 2.8875 - val_accuracy: 0.4558 - val_loss: 2.2943\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.3231 - loss: 2.4203 - val_accuracy: 0.6851 - val_loss: 1.6115\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.4893 - loss: 1.8153 - val_accuracy: 0.8877 - val_loss: 0.9391\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.6723 - loss: 1.2479 - val_accuracy: 0.9494 - val_loss: 0.4745\n",
            "Epoch 7/10\n",
            "\u001b[1m43/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7783 - loss: 0.8302"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/tree_species_classifier.h5')\n",
        "print(\"✅ Model saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "ZjAepvfNkm9c",
        "outputId": "003f7576-06de-4065-d61d-a1a2810b287c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-961756793.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/tree_species_classifier.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Model saved successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok tensorflow\n",
        "!npm install -g localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyhPFwW4mpzN",
        "outputId": "fdb80325-a20b-4959-c8b2-01bbbcc7acaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Using cached streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pyngrok\n",
            "  Using cached pyngrok-7.2.13-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.13-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.13 streamlit-1.47.1 watchdog-6.0.0\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "changed 22 packages in 593ms\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHDgAXq2mesB",
        "outputId": "411e9e2c-0985-4573-e608-107071d582dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load the model from Google Drive\n",
        "model = load_model('/content/drive/MyDrive/tree_species_classifier.h5')\n",
        "\n",
        "class_names = ['Ashoka', 'Banyan', 'Neem', 'Palm', 'Peepal']\n",
        "\n",
        "st.set_page_config(page_title=\"Tree Species Classifier 🌿\", layout=\"centered\")\n",
        "st.title(\"🌳 Tree Species Image Classifier\")\n",
        "st.markdown(\"Upload an image of a leaf/tree and get the predicted species!\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = Image.open(uploaded_file)\n",
        "    st.image(img, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction) * 100\n",
        "\n",
        "    st.success(f\"🌿 Predicted Species: **{predicted_class}** ({confidence:.2f}% confidence)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR0drh9Gmx7X",
        "outputId": "68970406-e50e-4cfd-9cc1-264c47e0926f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPqXSLTfm8NN",
        "outputId": "ad88093a-2787-479a-db90-bac104688665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c172239b",
        "outputId": "f6b70631-69a7-4770-eef4-de31d87df4e0"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "authtoken = getpass.getpass()\n",
        "ngrok.set_auth_token(authtoken)\n",
        "\n",
        "# Now try connecting again\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"🌐 Streamlit app is live at: {public_url}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "··········\n",
            "🌐 Streamlit app is live at: NgrokTunnel: \"https://7acda9e4f473.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaq77bmSNdO5",
        "outputId": "7d225f9c-2b0f-4de3-db74-ee86682947fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20230213_065401.jpg\t\t        IMG_20210814_164630.jpg\n",
            "'Certificate - SmartInternz (1).pdf'    IMG_20210814_164709.jpg\n",
            "'Colab Notebooks'\t\t        IMG_20210814_164739.JPG\n",
            " e7dab1c168ae5a2b485782d69a34291a.jpg   IMG_20210814_164801.jpg\n",
            " IMG_20190115_120330_Burst06.jpg        IMG_20210814_164835.jpg\n",
            " IMG_20190116_105446_Burst01.jpg        IMG_20210814_165131.jpg\n",
            " IMG_20190116_110415.jpg\t        IMG_20210814_165155.jpg\n",
            " IMG_20190116_110420.jpg\t        IMG_20210814_165250.JPG\n",
            " IMG_20190116_110444.jpg\t        IMG_20210814_165341.JPG\n",
            " IMG-20191021-WA0035.jpg\t        IMG_20210814_165420.JPG\n",
            " IMG-20191027-WA0053.jpg\t        IMG_20210814_165500.JPG\n",
            " IMG-20191027-WA0054.jpg\t        IMG_20210814_165558.jpg\n",
            " IMG-20191027-WA0055.jpg\t        IMG_20210814_165624.jpg\n",
            " IMG-20191027-WA0056.jpg\t        IMG_20210814_165644.jpg\n",
            " IMG-20191027-WA0057.jpg\t        IMG_20210814_165659.jpg\n",
            " IMG-20191027-WA0060.jpg\t        IMG_20210814_165721.jpg\n",
            " IMG-20191027-WA0061.jpg\t        IMG_20210814_165735.JPG\n",
            " IMG-20191027-WA0063.jpg\t        IMG_20210814_165747.jpg\n",
            " IMG-20191027-WA0065.jpg\t        IMG_20210814_165806.jpg\n",
            " IMG-20191027-WA0066.jpg\t        IMG_20210814_165827.jpg\n",
            " IMG-20191027-WA0067.jpg\t       'IMG_20210814_165846 (1).jpg'\n",
            " IMG-20191027-WA0068.jpg\t        IMG_20210814_165846.jpg\n",
            " IMG-20191027-WA0071.jpg\t        IMG_20210814_165854.jpg\n",
            " IMG-20191027-WA0160.jpg\t        IMG_20210814_165903.jpg\n",
            " IMG-20191027-WA0161.jpg\t        IMG_20210814_165927.JPG\n",
            " IMG-20191027-WA0162.jpg\t        IMG_20210814_165942.jpg\n",
            " IMG-20191027-WA0164.jpg\t        IMG_20210814_170039.jpg\n",
            " IMG-20191027-WA0165.jpg\t        IMG_20210814_170223.jpg\n",
            " IMG-20191027-WA0166.jpg\t        IMG_20210814_172539.jpg\n",
            " IMG-20191027-WA0168.jpg\t        IMG_20210814_172545.jpg\n",
            " IMG-20191027-WA0169.jpg\t        IMG_20210814_172634.jpg\n",
            " IMG-20191027-WA0173.jpg\t        IMG_20210814_172644.jpg\n",
            " IMG-20191027-WA0174.jpg\t        IMG_20210814_172710.jpg\n",
            " IMG-20191027-WA0175.jpg\t        IMG_20210814_172719.jpg\n",
            " IMG-20191027-WA0176.jpg\t        IMG_20210814_172744.jpg\n",
            " IMG-20191027-WA0177.jpg\t        IMG_20210814_172821.JPG\n",
            " IMG-20191027-WA0178.jpg\t        IMG_20210814_172840.JPG\n",
            " IMG-20191027-WA0179.jpg\t        IMG_20210814_172847.jpg\n",
            " IMG-20191027-WA0180.jpg\t        IMG_20210814_172921.JPG\n",
            " IMG-20191027-WA0181.jpg\t        IMG_20210814_172954.JPG\n",
            " IMG-20191027-WA0182.jpg\t        IMG_20210814_173210.JPG\n",
            " IMG-20191027-WA0183.jpg\t        IMG_20210816_144518.JPG\n",
            " IMG-20191027-WA0184.jpg\t        IMG_20210816_144538.JPG\n",
            " IMG-20191027-WA0185.jpg\t        IMG_20210816_144604.JPG\n",
            " IMG-20191027-WA0186.jpg\t        IMG_20210821_111326.JPG\n",
            " IMG-20191027-WA0187.jpg\t        IMG_20210821_111350.JPG\n",
            " IMG-20191027-WA0188.jpg\t        IMG_20210821_111439.JPG\n",
            " IMG-20191027-WA0189.jpg\t        IMG_20210928_201600.JPG\n",
            " IMG-20191027-WA0190.jpg\t        IMG_20210928_201620.JPG\n",
            " IMG-20191102-WA0067.jpg\t        IMG_20220102_192604.jpg\n",
            " IMG-20191102-WA0068.jpg\t        IMG_20221127_073438.jpg\n",
            " IMG-20191102-WA0069.jpg\t        IMG-20221211-WA0005.jpg\n",
            " IMG-20191102-WA0070.jpg\t        IMG-20221223-WA0001.jpg\n",
            " IMG-20191102-WA0071.jpg\t        IMG-20221223-WA0003.jpg\n",
            " IMG-20191102-WA0072.jpg\t        IMG-20221223-WA0005.jpg\n",
            " IMG-20191114-WA0108.jpg\t        IMG-20221230-WA0003.jpg\n",
            " IMG-20191114-WA0109.jpg\t       'IMG-20221231-WA0001 (1).jpg'\n",
            " IMG-20191114-WA0113.jpg\t        IMG-20221231-WA0001.jpg\n",
            " IMG-20191114-WA0114.jpg\t        IMG-20221231-WA0002.jpg\n",
            " IMG-20191114-WA0115.jpg\t        IMG-20221231-WA0003.jpg\n",
            " IMG-20191114-WA0116.jpg\t        IMG-20221231-WA0004.jpg\n",
            " IMG-20191114-WA0117.jpg\t        IMG-20221231-WA0005.jpg\n",
            " IMG-20191114-WA0118.jpg\t        IMG-20221231-WA0006.jpg\n",
            " IMG-20191114-WA0119.jpg\t        IMG-20221231-WA0007.jpg\n",
            " IMG-20191114-WA0120.jpg\t        IMG_20230101_110652.jpg\n",
            " IMG-20191114-WA0121.jpg\t        IMG-20230206-WA0002.jpg\n",
            " IMG-20191114-WA0122.jpg\t        IMG-20230206-WA0003.jpg\n",
            " IMG-20191114-WA0126.jpg\t        IMG-20230206-WA0004.jpg\n",
            " IMG-20191114-WA0127.jpg\t        IMG-20230206-WA0005.jpg\n",
            " IMG-20191114-WA0128.jpg\t        IMG-20230206-WA0006.jpg\n",
            " IMG-20191114-WA0129.jpg\t        IMG-20230206-WA0007.jpg\n",
            " IMG-20191114-WA0131.jpg\t        IMG-20230222-WA0014_resized.jpg\n",
            " IMG-20191114-WA0132.jpg\t        IMG-20230226-WA0000.jpg\n",
            " IMG-20191114-WA0133.jpg\t        IMG-20230226-WA0001.jpg\n",
            " IMG-20200110-WA0026.jpg\t        IMG-20230226-WA0002.jpg\n",
            " IMG-20200110-WA0027.jpg\t        IMG-20230226-WA0003.jpg\n",
            " IMG-20200110-WA0029.jpg\t        IMG-20230226-WA0004.jpg\n",
            " IMG-20200110-WA0030.jpg\t        IMG-20230226-WA0005.jpg\n",
            " IMG-20200110-WA0031.jpg\t        IMG-20230226-WA0006.jpg\n",
            " IMG-20200110-WA0032.jpg\t        IMG-20230226-WA0007.jpg\n",
            " IMG-20200110-WA0033.jpg\t        IMG-20230226-WA0008.jpg\n",
            " IMG-20200417-WA0001.jpg\t       'INDIA-A TOURIST PARADISE.pptx'\n",
            " IMG-20200418-WA0000.jpg\t        Screenshot_2020_0418_105936.jpg\n",
            " IMG-20200418-WA0004.jpg\t        Screenshot_2020_0418_182402.jpg\n",
            " IMG-20200418-WA0005.jpg\t        Screenshot_2020_0418_182536.jpg\n",
            " IMG-20200418-WA0006.jpg\t        Screenshot_2021_1130_211338.png\n",
            " IMG-20200418-WA0010.jpg\t        Screenshot_20220302_194813.JPG\n",
            " IMG-20200418-WA0024.jpg\t        Screenshot_20220423_065842.JPG\n",
            " IMG-20200418-WA0025.jpg\t        Screenshot_20250627-222505.png\n",
            " IMG-20200418-WA0026.jpg\t        Snapchat-1090634876.mp4\n",
            " IMG-20200418-WA0027.jpg\t        Snapchat-1269512282.mp4\n",
            " IMG-20200418-WA0053.jpg\t        Snapchat-1304862609.mp4\n",
            " IMG-20200418-WA0054.jpg\t        Snapchat-1322851500.jpg\n",
            " IMG-20200418-WA0055.jpg\t        Snapchat-1396755916.jpg\n",
            " IMG-20200418-WA0056.jpg\t        Snapchat-1503724500.jpg\n",
            " IMG-20200418-WA0057.jpg\t        Snapchat-1511022068.jpg\n",
            " IMG-20200418-WA0058.jpg\t        Snapchat-1582438401.mp4\n",
            " IMG-20200418-WA0059.jpg\t        Snapchat-1708526323.jpg\n",
            " IMG-20200418-WA0060.jpg\t        Snapchat-1789331188.mp4\n",
            " IMG-20200418-WA0062.jpg\t        Snapchat-1917925382.jpg\n",
            " IMG-20200418-WA0063.jpg\t        Snapchat-1937608068.jpg\n",
            " IMG-20200418-WA0064.jpg\t        Snapchat-1987200480.jpg\n",
            " IMG-20200418-WA0066.jpg\t        Snapchat-2000286503.jpg\n",
            " IMG-20200418-WA0067.jpg\t        Snapchat-239475143.jpg\n",
            " IMG-20200418-WA0068.jpg\t        Snapchat-444403464.mp4\n",
            " IMG-20200418-WA0070.jpg\t        Snapchat-447488467.jpg\n",
            " IMG-20200418-WA0071.jpg\t        Snapchat-466224753.jpg\n",
            " IMG-20200418-WA0072.jpg\t        Snapchat-630237181.jpg\n",
            " IMG-20200418-WA0073.jpg\t        Snapchat-791673740.jpg\n",
            " IMG-20200418-WA0074.jpg\t        Snapchat-793708076.jpg\n",
            " IMG-20200418-WA0075.jpg\t        Snapchat-877924610.jpg\n",
            " IMG_20200520_224153.jpg\t        Snapchat-93319993.jpg\n",
            " IMG_20200520_224721.jpg\t        Snapchat-945092404.jpg\n",
            " IMG_20200821_103020.JPG\t        Snapchat-978205544.mp4\n",
            " IMG_20210812_113352.jpg\t        Snapchat-988821456.jpg\n",
            " IMG_20210814_133203.jpg\t        tree_species_classifier.h5\n",
            " IMG_20210814_133444.jpg\t        Tree_Species_Dataset\n",
            " IMG_20210814_164414.jpg\t        VID-20200311-WA0061.mp4\n",
            " IMG_20210814_164445.jpg\t        VID-20200314-WA0047.mp4\n",
            " IMG_20210814_164503.jpg\t        VID-20200315-WA0039.mp4\n",
            " IMG_20210814_164511.jpg\t        VID-20220324-WA0001.mp4\n",
            " IMG_20210814_164604.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths\n",
        "train_dir = '/content/drive/MyDrive/Tree_Species_Dataset/train'\n",
        "test_dir = '/content/drive/MyDrive/Tree_Species_Dataset/test'\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "test_data = test_datagen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Build model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(train_data.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(train_data, validation_data=test_data, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqfz73MPN5sb",
        "outputId": "c06a2372-df74-4695-df6e-83aa3fa01dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1607 images belonging to 31 classes.\n",
            "Found 1086 images belonging to 31 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 11s/step - accuracy: 0.0755 - loss: 5.0747 - val_accuracy: 0.1740 - val_loss: 2.8879\n",
            "Epoch 2/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - accuracy: 0.2561 - loss: 2.7437 - val_accuracy: 0.5470 - val_loss: 1.8292\n",
            "Epoch 3/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.5846 - loss: 1.6335 - val_accuracy: 0.9098 - val_loss: 0.6991\n",
            "Epoch 4/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - accuracy: 0.8906 - loss: 0.5453 - val_accuracy: 0.9908 - val_loss: 0.1025\n",
            "Epoch 5/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4s/step - accuracy: 0.9888 - loss: 0.0875 - val_accuracy: 0.9972 - val_loss: 0.0296\n",
            "Epoch 6/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 4s/step - accuracy: 0.9967 - loss: 0.0379 - val_accuracy: 0.9982 - val_loss: 0.0125\n",
            "Epoch 7/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - accuracy: 0.9997 - loss: 0.0063 - val_accuracy: 0.9991 - val_loss: 0.0074\n",
            "Epoch 8/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.9994 - loss: 0.0083 - val_accuracy: 0.9991 - val_loss: 0.0074\n",
            "Epoch 9/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - accuracy: 0.9989 - loss: 0.0070 - val_accuracy: 0.9991 - val_loss: 0.0066\n",
            "Epoch 10/10\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - accuracy: 0.9999 - loss: 0.0029 - val_accuracy: 0.9991 - val_loss: 0.0069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b87c1730810>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/tree_species_classifier.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxMUkRJ6ORkn",
        "outputId": "87928ad1-9519-47b5-92ba-66cfd2f7c135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Load model\n",
        "model = tf.keras.models.load_model(\"tree_species_classifier.h5\")\n",
        "\n",
        "# Define class names (update with your actual labels)\n",
        "class_names = ['Ashoka', 'Banyan', 'Neem', 'Palm', 'Peepal']\n",
        "\n",
        "# Streamlit UI\n",
        "st.set_page_config(page_title=\"🌳 Tree Species Classifier\", layout=\"centered\")\n",
        "st.title(\"🌿 Tree Species Classification\")\n",
        "st.write(\"Upload an image of a tree leaf or part to predict its species.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a tree image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "if uploaded_file is not None:\n",
        "    img = Image.open(uploaded_file).convert('RGB')\n",
        "    st.image(img, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    # Preprocess image\n",
        "    img_resized = img.resize((224, 224))\n",
        "    img_array = image.img_to_array(img_resized)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    st.success(f\"🌳 Predicted Species: **{predicted_class}** ({confidence*100:.2f}% confidence)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWyeOzmZXVLP",
        "outputId": "d1753031-560e-4ffc-cbc7-8feb8b391516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/tree_species_classifier.h5 tree_species_classifier.h5\n"
      ],
      "metadata": {
        "id": "--bmxXwfXaMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Set your ngrok authtoken here. Replace \"YOUR_AUTHTOKEN\" with your actual token.\n",
        "# For security, it's better to store this in Colab Secrets.\n",
        "# from google.colab import userdata\n",
        "# ngrok.set_auth_token(userdata.get('NGROK_AUTH_TOKEN'))\n",
        "\n",
        "# Alternatively, you can paste your token directly here (less secure)\n",
        "# authtoken = getpass.getpass(\"Enter your authtoken: \") # Using getpass is more secure than hardcoding\n",
        "# ngrok.set_auth_token(authtoken)\n",
        "\n",
        "# For simplicity in this example, we'll use an environment variable or hardcode (replace with your token)\n",
        "# Make sure to get your token from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# As a best practice, store this in Colab secrets\n",
        "# ngrok.set_auth_token(os.environ.get(\"NGROK_AUTH_TOKEN\", \"YOUR_AUTHTOKEN_HERE\")) # Replace \"YOUR_AUTHTOKEN_HERE\"\n",
        "\n",
        "# Let's try getting the token using getpass for better security than hardcoding\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "authtoken = getpass.getpass()\n",
        "ngrok.set_auth_token(authtoken)\n",
        "\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "!streamlit run streamlit_app.py &>/dev/null &\n",
        "\n",
        "# Open HTTP tunnel on port 8501\n",
        "# It might take a few moments for the streamlit app to start, so ngrok.connect might take a moment\n",
        "try:\n",
        "    public_url = ngrok.connect(addr=8501, proto=\"http\")\n",
        "    print(f\"🌐 Public URL: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while trying to connect ngrok: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irV7q7JbXikW",
        "outputId": "91972318-8073-43c2-c08b-8ddc15508fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:25:55+0000 lvl=warn msg=\"failed to open private leg\" id=db60780c9ffe privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:25:55+0000 lvl=warn msg=\"failed to open private leg\" id=172b2aa145f2 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:25:58+0000 lvl=warn msg=\"failed to open private leg\" id=6c9fad23640a privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:25:58+0000 lvl=warn msg=\"failed to open private leg\" id=af516b817b07 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:01+0000 lvl=warn msg=\"failed to open private leg\" id=7d2010418022 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:01+0000 lvl=warn msg=\"failed to open private leg\" id=3eeb70e3fbee privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:04+0000 lvl=warn msg=\"failed to open private leg\" id=e42192974772 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:04+0000 lvl=warn msg=\"failed to open private leg\" id=71fa187f144e privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:07+0000 lvl=warn msg=\"failed to open private leg\" id=06a92f05ebf3 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:07+0000 lvl=warn msg=\"failed to open private leg\" id=74f690374110 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:10+0000 lvl=warn msg=\"failed to open private leg\" id=9ea5a4f47eec privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:10+0000 lvl=warn msg=\"failed to open private leg\" id=eb11dbc1ddcf privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:13+0000 lvl=warn msg=\"failed to open private leg\" id=4a770f8e828a privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:13+0000 lvl=warn msg=\"failed to open private leg\" id=c4c1e2283523 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:16+0000 lvl=warn msg=\"failed to open private leg\" id=7e535287453f privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:16+0000 lvl=warn msg=\"failed to open private leg\" id=e123955f99ae privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:19+0000 lvl=warn msg=\"failed to open private leg\" id=c60506a4c938 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-08-04T09:26:19+0000 lvl=warn msg=\"failed to open private leg\" id=b24dfa17b95e privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 Public URL: NgrokTunnel: \"https://3a60028b352c.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model(\"tree_species_classifier.h5\")\n",
        "print(\"✅ Model loaded!\")\n",
        "\n",
        "# Check output layer\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "O40NqRKJYyZR",
        "outputId": "1673e835-b8a7-4b97-a396-4d3250a8cf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m186624\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m23,888,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │         \u001b[38;5;34m3,999\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">186624</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,888,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,999</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,911,393\u001b[0m (91.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,911,393</span> (91.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,911,391\u001b[0m (91.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,911,391</span> (91.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "class_names = sorted(os.listdir(\"/content/drive/MyDrive/Tree_Species_Dataset/train\"))\n",
        "print(class_names)\n",
        "print(\"Number of classes:\", len(class_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CokdnnjoZCJT",
        "outputId": "57fa058f-d017-4c85-cb8c-79c4558b8f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.git', 'amla', 'asopalav', 'babul', 'bamboo', 'banyan', 'bili', 'cactus', 'champa', 'coconut', 'garmalo', 'gulmohor', 'gunda', 'jamun', 'kanchan', 'kesudo', 'khajur', 'mango', 'motichanoti', 'neem', 'nilgiri', 'other', 'pilikaren', 'pipal', 'saptaparni', 'shirish', 'simlo', 'sitafal', 'sonmahor', 'sugarcane', 'vad']\n",
            "Number of classes: 31\n"
          ]
        }
      ]
    }
  ]
}